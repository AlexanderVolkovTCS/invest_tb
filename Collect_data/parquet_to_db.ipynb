{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b7ca64-ff8f-451c-bac7-666095db7992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/20 16:41:25 WARN Utils: Your hostname, nikolay resolves to a loopback address: 127.0.1.1; using 192.168.1.3 instead (on interface wlp2s0)\n",
      "22/05/20 16:41:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/nikolay/anaconda3/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/nikolay/anaconda3/lib/python3.7/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/nikolay/.ivy2/cache\n",
      "The jars for the packages stored in: /home/nikolay/.ivy2/jars\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-97c7dcf5-da34-4cca-96ea-8251517d7d68;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.postgresql#postgresql;42.2.5 in central\n",
      ":: resolution report :: resolve 162ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\torg.postgresql#postgresql;42.2.5 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-97c7dcf5-da34-4cca-96ea-8251517d7d68\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/9ms)\n",
      "22/05/20 16:41:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "22/05/20 16:41:26 WARN DependencyUtils: Local jar /home/nikolay/Projects/tinkoff-invest/Collect_data/postgresql-42.2.5.jar does not exist, skipping.\n",
      "22/05/20 16:41:26 INFO SparkContext: Running Spark version 3.2.1\n",
      "22/05/20 16:41:26 INFO ResourceUtils: ==============================================================\n",
      "22/05/20 16:41:26 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "22/05/20 16:41:26 INFO ResourceUtils: ==============================================================\n",
      "22/05/20 16:41:26 INFO SparkContext: Submitted application: tinkof-invest\n",
      "22/05/20 16:41:26 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 20480, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "22/05/20 16:41:26 INFO ResourceProfile: Limiting resource is cpu\n",
      "22/05/20 16:41:26 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "22/05/20 16:41:27 INFO SecurityManager: Changing view acls to: nikolay\n",
      "22/05/20 16:41:27 INFO SecurityManager: Changing modify acls to: nikolay\n",
      "22/05/20 16:41:27 INFO SecurityManager: Changing view acls groups to: \n",
      "22/05/20 16:41:27 INFO SecurityManager: Changing modify acls groups to: \n",
      "22/05/20 16:41:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nikolay); groups with view permissions: Set(); users  with modify permissions: Set(nikolay); groups with modify permissions: Set()\n",
      "22/05/20 16:41:27 INFO Utils: Successfully started service 'sparkDriver' on port 35045.\n",
      "22/05/20 16:41:27 INFO SparkEnv: Registering MapOutputTracker\n",
      "22/05/20 16:41:27 INFO SparkEnv: Registering BlockManagerMaster\n",
      "22/05/20 16:41:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "22/05/20 16:41:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "22/05/20 16:41:27 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "22/05/20 16:41:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-05dc7532-ef03-4bec-822a-663b7fa4c89e\n",
      "22/05/20 16:41:27 INFO MemoryStore: MemoryStore started with capacity 11.8 GiB\n",
      "22/05/20 16:41:27 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "22/05/20 16:41:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "22/05/20 16:41:27 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040\n",
      "22/05/20 16:41:28 ERROR SparkContext: Failed to add postgresql-42.2.5.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /home/nikolay/Projects/tinkoff-invest/Collect_data/postgresql-42.2.5.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:1935)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:1990)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$12(SparkContext.scala:503)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$12$adapted(SparkContext.scala:503)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:503)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "22/05/20 16:41:28 INFO SparkContext: Added file file:///home/nikolay/.ivy2/jars/org.postgresql_postgresql-42.2.5.jar at file:///home/nikolay/.ivy2/jars/org.postgresql_postgresql-42.2.5.jar with timestamp 1653054086830\n",
      "22/05/20 16:41:28 INFO Utils: Copying /home/nikolay/.ivy2/jars/org.postgresql_postgresql-42.2.5.jar to /tmp/spark-bad37872-ed4d-488e-83fe-bc974367c072/userFiles-27c42906-b69c-4074-b6cb-73f136faee82/org.postgresql_postgresql-42.2.5.jar\n",
      "22/05/20 16:41:28 INFO Executor: Starting executor ID driver on host 192.168.1.3\n",
      "22/05/20 16:41:28 INFO Executor: Fetching file:///home/nikolay/.ivy2/jars/org.postgresql_postgresql-42.2.5.jar with timestamp 1653054086830\n",
      "22/05/20 16:41:28 INFO Utils: /home/nikolay/.ivy2/jars/org.postgresql_postgresql-42.2.5.jar has been previously copied to /tmp/spark-bad37872-ed4d-488e-83fe-bc974367c072/userFiles-27c42906-b69c-4074-b6cb-73f136faee82/org.postgresql_postgresql-42.2.5.jar\n",
      "22/05/20 16:41:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38829.\n",
      "22/05/20 16:41:28 INFO NettyBlockTransferService: Server created on 192.168.1.3:38829\n",
      "22/05/20 16:41:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "22/05/20 16:41:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.3, 38829, None)\n",
      "22/05/20 16:41:28 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.3:38829 with 11.8 GiB RAM, BlockManagerId(driver, 192.168.1.3, 38829, None)\n",
      "22/05/20 16:41:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.3, 38829, None)\n",
      "22/05/20 16:41:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 38829, None)\n",
      "22/05/20 16:41:28 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "22/05/20 16:41:28 INFO SharedState: Warehouse path is 'file:/home/nikolay/Projects/tinkoff-invest/Collect_data/spark-warehouse'.\n",
      "22/05/20 16:41:29 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>tinkof-invest</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fcbf6073410>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from sqlalchemy import create_engine\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# initialise sparkContext\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.jars\", \"postgresql-42.2.5.jar\")\\\n",
    "    .config(\"spark.jars.packages\",\"org.postgresql:postgresql:42.2.5\")\\\n",
    "    .config('spark.driver.maxResultSize','20g').config(\"spark.executor.memory\", \"20g\")\\\n",
    "    .config(\"spark.driver.memory\",\"20g\").config(\"spark.executor.memory\",\"20g\")\\\n",
    "    .config(\"spark.shuffle.file.buffer\",'40').config(\"spark.scheduler.listenerbus.eventqueue.capacity\",\"10000000\")\\\n",
    "    .master(\"local\").appName(\"tinkof-invest\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", True)\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60de3e23-86c8-47ff-8925-c2add1e77927",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = spark.createDataFrame(pd.read_parquet('all_candles_hour.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "785671e9-653a-4d28-ac6e-b5b62c7ed59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_15 = spark.createDataFrame(pd.read_parquet('all_candles_15min.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6259d97f-c297-4234-a7c3-0c7afe66fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_5 = spark.createDataFrame(pd.read_parquet('all_candles_5min.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03e66ef3-36f5-4de8-b979-4bfd8e5baf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_1 = spark.createDataFrame(pd.read_parquet('all_candles_1min.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ed94fc-aaa5-4d03-a083-0bfa729785be",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"overwrite\"\n",
    "url = \"jdbc:postgresql://localhost:5432/shares\"\n",
    "properties = {\"user\": \"nikolay\",\"password\": \"Andone1\",\"driver\": \"org.postgresql.Driver\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "726ee064-13c0-4d9a-ab1d-dbad5524658a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[figi: string, time: timestamp, open: decimal(14,8), close: decimal(14,8), high: decimal(14,8), low: decimal(14,8), volume: double, is_complete: double]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3452d8e8-5674-406c-925d-fa0401097f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hour.write.jdbc(url=url, table=\"candles_hour\", mode=mode, properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94a529a7-6fab-46f2-a257-cfd0d0a5c207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "min_15.write.jdbc(url=url, table=\"candles_15min\", mode=mode, properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d9724b-370e-4112-952f-b68639281caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "min_5.write.jdbc(url=url, table=\"candles_5min\", mode=mode, properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca0e09b9-e766-4487-b6bb-440e53760639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "min_1.write.jdbc(url=url, table=\"candles_1min\", mode=mode, properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62cdf18-b7f0-4f09-a9ae-88fff696f75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>figi</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>is_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>2022-02-22 07:00:00+00:00</td>\n",
       "      <td>0.00364500</td>\n",
       "      <td>0.00340000</td>\n",
       "      <td>0.00364500</td>\n",
       "      <td>0.00300500</td>\n",
       "      <td>954</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>2022-02-22 08:00:00+00:00</td>\n",
       "      <td>0.00339500</td>\n",
       "      <td>0.00337000</td>\n",
       "      <td>0.00349000</td>\n",
       "      <td>0.00332500</td>\n",
       "      <td>293</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>2022-02-22 09:00:00+00:00</td>\n",
       "      <td>0.00341500</td>\n",
       "      <td>0.00343500</td>\n",
       "      <td>0.00344000</td>\n",
       "      <td>0.00336500</td>\n",
       "      <td>56</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>2022-02-22 10:00:00+00:00</td>\n",
       "      <td>0.00344000</td>\n",
       "      <td>0.00346500</td>\n",
       "      <td>0.00346500</td>\n",
       "      <td>0.00340000</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>2022-02-22 11:00:00+00:00</td>\n",
       "      <td>0.00344000</td>\n",
       "      <td>0.00345500</td>\n",
       "      <td>0.00349000</td>\n",
       "      <td>0.00344000</td>\n",
       "      <td>39</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>2022-05-19 11:00:00+00:00</td>\n",
       "      <td>0.00356000</td>\n",
       "      <td>0.00356000</td>\n",
       "      <td>0.00356000</td>\n",
       "      <td>0.00356000</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>2022-05-19 12:00:00+00:00</td>\n",
       "      <td>0.00356500</td>\n",
       "      <td>0.00356500</td>\n",
       "      <td>0.00356500</td>\n",
       "      <td>0.00356500</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>2022-05-19 13:00:00+00:00</td>\n",
       "      <td>0.00355000</td>\n",
       "      <td>0.00356500</td>\n",
       "      <td>0.00356500</td>\n",
       "      <td>0.00355000</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>2022-05-19 14:00:00+00:00</td>\n",
       "      <td>0.00355000</td>\n",
       "      <td>0.00353500</td>\n",
       "      <td>0.00356000</td>\n",
       "      <td>0.00353500</td>\n",
       "      <td>43</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>2022-05-19 15:00:00+00:00</td>\n",
       "      <td>0.00355500</td>\n",
       "      <td>0.00355500</td>\n",
       "      <td>0.00356500</td>\n",
       "      <td>0.00355500</td>\n",
       "      <td>65</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    figi                      time        open       close        high  \\\n",
       "0   None 2022-02-22 07:00:00+00:00  0.00364500  0.00340000  0.00364500   \n",
       "1   None 2022-02-22 08:00:00+00:00  0.00339500  0.00337000  0.00349000   \n",
       "2   None 2022-02-22 09:00:00+00:00  0.00341500  0.00343500  0.00344000   \n",
       "3   None 2022-02-22 10:00:00+00:00  0.00344000  0.00346500  0.00346500   \n",
       "4   None 2022-02-22 11:00:00+00:00  0.00344000  0.00345500  0.00349000   \n",
       "..   ...                       ...         ...         ...         ...   \n",
       "4   None 2022-05-19 11:00:00+00:00  0.00356000  0.00356000  0.00356000   \n",
       "5   None 2022-05-19 12:00:00+00:00  0.00356500  0.00356500  0.00356500   \n",
       "6   None 2022-05-19 13:00:00+00:00  0.00355000  0.00356500  0.00356500   \n",
       "7   None 2022-05-19 14:00:00+00:00  0.00355000  0.00353500  0.00356000   \n",
       "8   None 2022-05-19 15:00:00+00:00  0.00355500  0.00355500  0.00356500   \n",
       "\n",
       "           low  volume  is_complete  \n",
       "0   0.00300500     954         True  \n",
       "1   0.00332500     293         True  \n",
       "2   0.00336500      56         True  \n",
       "3   0.00340000      26         True  \n",
       "4   0.00344000      39         True  \n",
       "..         ...     ...          ...  \n",
       "4   0.00356000       2         True  \n",
       "5   0.00356500      13         True  \n",
       "6   0.00355000      10         True  \n",
       "7   0.00353500      43         True  \n",
       "8   0.00355500      65         True  \n",
       "\n",
       "[326 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet('debug/BBG000Q7GG57_hour_from_2022-02-21_to2022-05-20.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827f0a78-cf34-48cd-b4cb-e7a246373e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
